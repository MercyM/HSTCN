# --- QMIX specific parameters ---

# use epsilon greedy action selector
action_selector:
  type: "epsilon_greedy"
  epsilon_start: 1.0
  epsilon_finish: 0.05
  epsilon_anneal_time: 50000

macro_action_selector:
  type: "epsilon_greedy"
  epsilon_start: 1.0
  epsilon_finish: 0.05
  epsilon_anneal_time: 50000

runner: "episode"

buffer_size: 5000

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
learner: "haven_learner"
double_q: True
mixer: "qmix"
macro_mixer: "graphmix"
value_mixer: "qmix"
name: "haven"
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64

n_subgoals: 70 #不同场景不一致 3s5z :11 8m:14 MMM2: 18 27m_vs_30m:36 5m_vs_6m:12 8m_vs_9m:15 2c_vs_64zg:70,70 训练时候需要把这行中文删掉
k: 12 #3 27m_vs_30m:12

macro_mac: "macro_mac"
mean_weight: True
intrinsic_switch: 1
reward_switch: 1

agent: "macro"

lambda_local: 1